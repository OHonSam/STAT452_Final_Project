---
title: "Activity_2_Happiness"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(car)
library(MASS)
library(corrplot)
library(reshape2)
library(faraway)
library(caret)
library(lmtest)
library(RColorBrewer)
```
## 0. Preprocess data
```{r}
# Read the CSV files into data frames
df_a <- read.csv("world-happiness-report-2021.csv")
df_b <- read.csv("world-happiness-report.csv")

# Create a mapping from df_a
country_regions <- df_a %>% 
  dplyr::select(Country, Region) %>% 
  distinct()

# Add the 'Region' column to df_b
df_b <- df_b %>% 
  left_join(country_regions, by = "Country")

# Reorder the column (move to after the Country column)
df_b <- df_b %>% relocate(Region, .after = Country)
write.csv(df_b, "world-happiness-report-with-regions.csv", row.names = FALSE)
```
## 1. Import data
```{r}
data <- read.csv("world-happiness-report-with-regions.csv", header = TRUE, sep = ",")
attach(data)
```

```{r}
missing_values <- sapply(data, function(x) sum(is.na(x)))
print(missing_values)
```
## 2. Clean data
```{r}
data_clean <- data %>%
  group_by(Country) %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))
data_clean <- na.omit(data_clean)
data_clean <- unique(data_clean)
dim(data_clean)
str(data_clean)
# 1708 / 19
```

```{r}
str(data_clean)
attach(data_clean)
```
##3 Descriptive statistics
### Visualization
```{r}
ggplot(data_clean, aes(y = Freedom.to.make.life.choices)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Freedom", y = " ") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )

ggplot(data, aes(y = Life.Ladder)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Life Ladder", y = " ") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )

ggplot(data_clean, aes(y = Positive.affect)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Positive", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )

ggplot(data_clean, aes(y = Negative.affect)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Negative", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )

ggplot(data_clean, aes(y = Generosity)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Generosity", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )
ggplot(data_clean, aes(y = Log.GDP.per.capita)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Log GDP", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )

ggplot(data_clean, aes(y = Social.support)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Social support", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )

ggplot(data_clean, aes(y = Healthy.life.expectancy.at.birth)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Healthy life expectancy", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )
ggplot(data_clean, aes(y = Perceptions.of.corruption)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Perceptions of corruption", y = "") + 
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title horizontally
    axis.title.y = element_text(size = 16),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 14)
  )
```
### Cook's distance to remove outliers
```{r}
model <- lm(Life.Ladder ~ . -Country - Region, data = data_clean)

# Calculate Cook's distance
cooksd <- cooks.distance(model)

# Plot Cook's distance
plot(cooksd, pch="*", cex=2, main="Cook's distance", ylab="Cook's distance")
abline(h = 4/length(cooksd), col="red")  # Add a horizontal line at 4/n
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/length(cooksd),names(cooksd),""), col="red")

# Identify influential points
influential <- as.numeric(names(cooksd)[(cooksd > 4/length(cooksd))])

# Optionally, remove influential points from the dataset
data_clean <- data_clean[-influential, ]

```
### Summarize the data
```{r}
dim(data_clean)
```

```{r}
# Create a summary of the year data
year_summary <- data_clean %>%
  count(year) %>%
  mutate(percentage = n / sum(n)) %>%
  mutate(year_group = ifelse(percentage < 0.055, "Other", as.character(year))) %>%
  group_by(year_group) %>%
  summarize(percentage = sum(percentage)) %>%
  arrange(desc(percentage))

# Generate a color palette
n_colors <- nrow(year_summary)
colors <- colorRampPalette(brewer.pal(8, "Set3"))(n_colors)

# Create the pie chart
ggplot(year_summary, aes(x = "", y = percentage, fill = year_group)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  theme_void() +
  labs(title = "Number of countries taking the survey (2005-2020)", fill = "Year") +
  geom_text(aes(label = paste0(round(percentage * 100, 1), "%")), 
            position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = colors, name = "Year") +
  theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        legend.title = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 10))
# More countries take survey from 2006
```

```{r}
hist(data_clean$Log.GDP.per.capita, breaks = 20)
# Left-skewed distribution, many countries have average log GDP per capita
```

```{r}
hist(Social.support, breaks = 30)
# average of national responses on the question... 
# left-skewed, most responses were yes
# highest values 0.9
```

```{r}
hist(Freedom.to.make.life.choices, breaks = 30)
# average of national responses on the question... 
# left-skewed, most responses were yes
```

```{r}
hist(Healthy.life.expectancy.at.birth, breaks = 40)
# average life expectancy
# most people expect their age between 65-68 or 71-72
```
```{r}
hist(Generosity, breaks = 30)
# Residual of regressing national average of response to the question...
# residual -> negative is possible
# most people say no
```
```{r}
hist(Perceptions.of.corruption, breaks = 30)
# average of national responses on the 2 questions on corruption
# most people response 2 yes
```
```{r}
hist(Positive.affect, breaks = 30)
# average of 3 positive affect measures
# left-skewed
```
```{r}
hist(Negative.affect, breaks = 30)
# average of 3 negative effects per country
# right-skewed
# most people feels little negative effect
```
```{r}
hist(Life.Ladder, breaks = 30)
# the ladder score (happiness score), from 0 to 10
# looks approximately normal
```

```{r}
plot(Life.Ladder ~ Negative.affect, data = data_clean)
# Lots of outliers in the Negative.affect plot
# Life.Ladder plot looks normal
# The relationship between the two variables is not clear
# correlation: -0.286
cor(Life.Ladder, Negative.affect)
```

```{r}
plot(Life.Ladder ~ Positive.affect, data = data_clean)
cor(Life.Ladder, Positive.affect)
# Relationship: positive relationship between the two variables, but not quite clear (0.562)
```

```{r}
plot(Life.Ladder ~ Log.GDP.per.capita, data = data_clean)
cor(Life.Ladder, Log.GDP.per.capita)
# Relationship: positive relationship between the two variables, obvious positive relationship
```

```{r}
plot(Life.Ladder ~ Healthy.life.expectancy.at.birth, data = data_clean)
cor(Life.Ladder, Healthy.life.expectancy.at.birth)
# Relationship: positive relationship between the two variables, clear relationship
```

```{r}
plot(Life.Ladder ~ Social.support, data = data_clean)
cor(Life.Ladder, Social.support)
# Relationship: positive relationship between the two variables, clear relationship
```

```{r}
plot(Life.Ladder ~ Freedom.to.make.life.choices, data = data_clean)
cor(Life.Ladder, Freedom.to.make.life.choices)
# Relationship: seems positive, but not quite clear
```

```{r}
plot(Life.Ladder ~ Generosity, data = data_clean)
cor(Life.Ladder, Generosity)
# Relationship: no relationship
```

```{r}
plot(Life.Ladder ~ Perceptions.of.corruption, data = data_clean)
cor(Life.Ladder, Perceptions.of.corruption)
# Relationship: negative relationship, but not clear
```

```{r}
boxplot(Life.Ladder ~ year, data = data_clean)
# Shows a (quite) consistent ladder score over years
```
```{r}
boxplot(Life.Ladder ~ Region, data = data_clean)
```
## 4. Model Building

```{r}
data_clean <- as.data.frame(data_clean)
data_clean$Region <- as.factor(data_clean$Region)

# Create dummy variables
dummy_vars <- model.matrix(~ Region, data = data_clean)

# Remove the intercept column
dummy_vars <- dummy_vars[, -1]

# Combine the dummy variables with the original data frame
data_clean <- cbind(data_clean, dummy_vars)

data_clean <- dplyr::select(data_clean, -Country)
data_clean <- dplyr::select(data_clean, -Region)
# Display the first few rows of the data frame with dummy variables
head(data_clean)
```
### Split data train and test
```{r}
set.seed(1)
sample_size <- floor(0.8 * nrow(data_clean))
train_indices <- sample(seq_len(nrow(data_clean)), size = sample_size)
data_train <- data_clean[train_indices, ]
data_test <- data_clean[-train_indices, ]
detach(data_clean)
attach(data_train)
```

```{r}
model = lm(Life.Ladder ~ . , data = data_train)
summary(model)
```
### Check multicollinearity
```{r}
vif_values = vif(model)
max_vif <- max(vif_values)
while (max_vif > 10) {
  max_vif_var <- names(vif_values[vif_values == max_vif])
  data_train <- data_train[ , !(names(data_train) %in% max_vif_var)]
  model <- lm(Life.Ladder ~ . , data = data_train)
  vif_values <- vif(model)
  max_vif <- max(vif_values)
}
```


```{r}
model <- lm(Life.Ladder ~ . , data = data_train)
vif(model)
print(max(vif(model)))
```

```{r}
# Test the collinearity of the healthy life variable
test <- lm(Healthy.life.expectancy.at.birth ~ . - Life.Ladder, data = data_train)
summary(test)
# R^2 = 0.85 -> high collinearity -> remove the variable
```
```{r}
model <- lm(Life.Ladder ~ . - Healthy.life.expectancy.at.birth, data = data_train)
summary(model)
vif(model)
```
### Variable selection
```{r}
modFull = lm(Life.Ladder ~ . - Healthy.life.expectancy.at.birth, data = data_train)
modZero = lm(Life.Ladder ~ 1, data = data_train)
modInter = lm(Life.Ladder~ Log.GDP.per.capita + Social.support + Freedom.to.make.life.choices + Generosity
+ Perceptions.of.corruption + Positive.affect + Negative.affect, data = data_train)
```

```{r}
model2 = MASS::stepAIC(modInter, direction = "both", scope = list(lower = modZero, upper = modFull), k = 2)
summary(model2)
```

```{r}
model3 = MASS::stepAIC(modInter, direction = "both", scope = list(lower = modZero, upper = modFull), k = log(nrow(data_train)))
summary(model3)
```

```{r}
anova(model2, model3)
# Since P-value < 0.05, we reject H0 and conclude that the model with more variables is better
# However, it's not worth to keep the model with more variables but less than 1% improvement in R^2
# We will keep the model with fewer variables
```
### Hypothesis testing
```{r}
shapiro.test(residuals(model3))
par(mfrow=c(1,2))

hist_residuals <- residuals(model3)
hist(hist_residuals, main = "Residuals Histogram", xlab = "Residuals", breaks = 100, probability = TRUE)

mean_residuals <- mean(hist_residuals)
sd_residuals <- sd(hist_residuals)
curve(dnorm(x, mean = mean_residuals, sd = sd_residuals), col = "red", add = TRUE)

qqnorm(hist_residuals, main = "Q-Q Plot of Residuals")
qqline(hist_residuals, col = "red")
```

```{r}
bp_test <- bptest(model3)
print(bp_test)
# Fail BP test, meaning that the variance is not constant -> Apply Box-cox transformation
```
### Box-cox transformation

```{r}
# Life.Ladder ~ Log.GDP.per.capita + Social.support + Freedom.to.make.life.choices + 
#    Generosity + Perceptions.of.corruption + Positive.affect + 
#    `RegionLatin America and Caribbean` + `RegionSoutheast Asia` + 
#    `RegionSub-Saharan Africa` + `RegionWestern Europe` + `RegionNorth America and ANZ`
model_cox = lm(Life.Ladder~ Log.GDP.per.capita + Social.support + Freedom.to.make.life.choices + 
    Generosity + Perceptions.of.corruption + Positive.affect + `RegionLatin America and Caribbean`  , data = data_train)
summary(model_cox)
boxcox_result <- boxcox(model_cox, plotit = TRUE)
lambda <- boxcox_result$x
log_likelihood <- boxcox_result$y
best_lambda <- lambda[which.max(log_likelihood)]

# Print the best lambda
print(best_lambda)
```

```{r}
best_lambda = 1.8
model_cox = lm(((((Life.Ladder)^best_lambda) - 1)/best_lambda) ~ Log.GDP.per.capita + Social.support + Freedom.to.make.life.choices + Generosity + Perceptions.of.corruption + Positive.affect + `RegionLatin America and Caribbean`  , data = data_train)
summary(model_cox)
```

## 5. Model Diagnostics
```{r}
# Shapiro test
shapiro.test(residuals(model_cox))
par(mfrow=c(1,2))

hist_residuals <- residuals(model_cox)
hist(hist_residuals, main = "Residuals Histogram", xlab = "Residuals", breaks = 100, probability = TRUE)

mean_residuals <- mean(hist_residuals)
sd_residuals <- sd(hist_residuals)
curve(dnorm(x, mean = mean_residuals, sd = sd_residuals), col = "red", add = TRUE)

qqnorm(hist_residuals, main = "Q-Q Plot of Residuals")
qqline(hist_residuals, col = "red")

# Breusch-Pagan test
bp_test <- bptest(model_cox)
print(bp_test)

# Durbin-Watson test
durbinWatsonTest(model_cox)
```

## 6,7. Prediction and evaluation
Using cross validation k-folds
```{r}
set.seed(1)
# Define a train control with k-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation

# Define the formula for the model
formula <- as.formula(paste0("((Life.Ladder^", best_lambda, " - 1)/", best_lambda, ") ~ Log.GDP.per.capita + Social.support + Freedom.to.make.life.choices + Generosity + Perceptions.of.corruption + Positive.affect + `RegionLatin America and Caribbean`"))

# Train the model using the training data
cv_model <- train(formula, data = data_train, method = "lm", trControl = train_control)

# Predict using the cross-validated model on the test data
predictions <- predict(cv_model, newdata = data_test)

# Calculate performance metrics on the test data
actual_values <- data_test$Life.Ladder
predict_values <- (predictions*best_lambda + 1) ^ (1/best_lambda)
results <- data.frame(
  Actual = actual_values,
  Predicted = predict_values
)

# Print the results
print(results)

# Calculate and print RMSE and R-squared
rmse <- sqrt(mean((results$Actual - results$Predicted)^2))
r_squared <- cor(results$Actual, results$Predicted)^2
cat("RMSE:", rmse, "\n")
cat("R-squared:", r_squared, "\n")
```